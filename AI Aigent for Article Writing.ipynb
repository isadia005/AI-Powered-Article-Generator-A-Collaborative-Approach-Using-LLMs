{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLgWe7YfJONx"
      },
      "source": [
        "\n",
        "\n",
        "## **LLM Assignment 2: AI Agent (Paper Writer)**  \n",
        "---\n",
        "\n",
        "## **üìå Description**  \n",
        "\n",
        "Make an AI agent using two LLMs. The first LLM will write/rewrite text, and the second LLM will critique the generated response.  \n",
        "The user will input the article title, a short description of the article, and the length of the article in number of words.  \n",
        "In response, the agent will produce the article as a **PDF/Word file**.\n",
        "\n",
        "### üîç **Hint:**  \n",
        "The article may be written in the following sequence:  \n",
        "- **Step 1:** LLM1 makes a broad structure ‚Üí LLM2 critiques/recommends ‚Üí LLM1 rewrites.  \n",
        "- **Step 2:** LLM1 writes on **Point 1** ‚Üí LLM2 critiques/recommends ‚Üí LLM1 rewrites.  \n",
        "- **Step 2 continues in a loop until the end of the article.**  \n",
        "\n",
        "---\n",
        "\n",
        "## **üìù Student Details**\n",
        "- **üë§ Name:** Sadia Iqbal  \n",
        "- **üìå Roll Number:** 00000500275  \n",
        "- **üìö Course:** Large Language Models  \n",
        "- **üéì University:** Military College of Signals, NUST  \n",
        "- **üìù Submitted to:** Brig Dr Asif Masood  \n",
        "- **üìÖ Batch:** MSSE-31  \n",
        "- **üìÜ Date:** 12 February 2025  \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri-oJUBNweIM"
      },
      "source": [
        "## **1Ô∏è‚É£ Step 1: Install Required Libraries**  \n",
        "\n",
        "### **üîπ What is Happening in This Step?**  \n",
        "\n",
        "This command installs the necessary Python libraries:  \n",
        "\n",
        "- **requests** ‚Üí For making API calls (e.g., interacting with LLMs).  \n",
        "- **python-docx** ‚Üí For creating and editing Word documents.  \n",
        "- **fpdf** ‚Üí For generating PDF files.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6IHW4e48hq3",
        "outputId": "14b0106e-edd0-491f-f9d3-80b5e1a8fe86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests python-docx fpdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn_6OjgtOM3I"
      },
      "source": [
        "## **2Ô∏è‚É£ Step 2: Import Necessary Libraries**  \n",
        "\n",
        "### **üîπ What is Happening in This Step?**  \n",
        "\n",
        "I am importing essential Python libraries:  \n",
        "\n",
        "- **requests** ‚Üí To make API calls (e.g., interacting with LLMs).  \n",
        "- **json** ‚Üí To handle JSON data structures.  \n",
        "- **IPython.display** (Markdown) ‚Üí To display formatted text in the notebook.  \n",
        "- **fpdf** ‚Üí To generate PDF files.  \n",
        "- **docx (Document)** ‚Üí To create and edit Word documents.  \n",
        "- **os** ‚Üí To interact with your operating system such as when using .env files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dNh8MZvvOOJm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "from IPython.display import display, Markdown\n",
        "from fpdf import FPDF\n",
        "from docx import Document\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbBBqrR1OT-Q"
      },
      "source": [
        "<h2>3Ô∏è‚É£ Step 3: Store API Keys Securely</h2>\n",
        "\n",
        "<h3>üîπ What is Happening in This Step?</h3>\n",
        "<p>Instead of writing API keys directly in the code, I am storing them in a hidden <code>.env</code> file to keep them <b>safe</b> and <b>private</b>.</p>\n",
        "\n",
        "<h3>üîπ How Are API Keys Stored?</h3>\n",
        "<ol>\n",
        "  <li><b>Created a <code>.env</code> file</b> and saved API keys inside it.</li>\n",
        "  <li><b>Loaded the <code>.env</code> file</b> in Colab using <code>load_dotenv()</code>.</li>\n",
        "  <li><b>Fetched the API keys</b> securely using <code>os.getenv()</code>.</li>\n",
        "</ol>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload your .env file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "pNjFdppijlBb",
        "outputId": "c1c6c185-aee1-4e45-8a19-e68adedde2cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f62e8409-2330-439c-a850-218474b061b3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f62e8409-2330-439c-a850-218474b061b3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving .env.txt to .env (1).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()  # Load the .env file\n",
        "\n",
        "# Now, fetch your API keys securely\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "print(\"üîë API Keys Loaded Securely!\")  # Just to check if it worked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzeT9eaVkZFA",
        "outputId": "8dcd9d56-324c-4344-d686-880c012b6b18"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë API Keys Loaded Securely!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPzvCjcVPhYR"
      },
      "source": [
        "## **4Ô∏è‚É£ Step 4: Test API Integrations**  \n",
        "\n",
        "### **üîπ What is Happening in This Step?**  \n",
        "\n",
        "I am testing API connectivity for three different LLMs:  \n",
        "\n",
        "- **Groq (Llama3-8B-8192)** ‚Üí Sends a test message to Groq‚Äôs Llama model and prints the response.  \n",
        "- **Mistral (Mistral-Tiny)** ‚Üí Sends a test message to Mistral‚Äôs API and prints the response.  \n",
        "- **Gemini (Gemini-Pro)** ‚Üí Sends a test prompt to Google's Gemini model and prints the response.  \n",
        "\n",
        "üîπ **Error Handling for Gemini:** If an error occurs while calling the Gemini API, it is caught and displayed.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV1OIhWIPbsR",
        "outputId": "c01919e9-0188-4076-e86a-fbae8de0feb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Groq Response: {'id': 'chatcmpl-b8584940-80fc-46ac-9c37-f109ea8557bc', 'object': 'chat.completion', 'created': 1739372591, 'model': 'llama3-8b-8192', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Hello! I'm just a language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help with any questions or tasks you have! It's great to chat with you. How can I assist\"}, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'queue_time': 0.131982595, 'prompt_tokens': 16, 'prompt_time': 0.003156398, 'completion_tokens': 50, 'completion_time': 0.041666667, 'total_tokens': 66, 'total_time': 0.044823065}, 'system_fingerprint': 'fp_a97cfe35ae', 'x_groq': {'id': 'req_01jkxayyp7ezqapk9tyx4vtca8'}}\n"
          ]
        }
      ],
      "source": [
        "# Test Groq (Llama) API\n",
        "def test_groq():\n",
        "    url = \"https://api.groq.com/openai/v1/chat/completions\"  # Groq API endpoint\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {os.getenv('GROQ_API_KEY')}\",  # Securely fetch API key\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"llama3-8b-8192\",  # Change model if needed\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}],\n",
        "        \"max_tokens\": 50\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    return response.json()\n",
        "\n",
        "# Test the API\n",
        "groq_response = test_groq()\n",
        "print(\"Groq Response:\", groq_response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlHT2oe4Pmta",
        "outputId": "ef3b74e0-ee80-4ed8-defb-565ab66d265a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistral Response: {'id': '06f28267abe84298971f4121d99fff35', 'object': 'chat.completion', 'created': 1739372601, 'model': 'mistral-tiny', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'tool_calls': None, 'content': \"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\"}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 9, 'total_tokens': 45, 'completion_tokens': 36}}\n"
          ]
        }
      ],
      "source": [
        "#Test Mistral API\n",
        "def test_mistral():\n",
        "    url = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {os.getenv('MISTRAL_API_KEY')}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"mistral-tiny\",  # Change model if needed\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}],\n",
        "        \"max_tokens\": 50\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    return response.json()\n",
        "\n",
        "# Test the API\n",
        "mistral_response = test_mistral()\n",
        "print(\"Mistral Response:\", mistral_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "hJIrVMRCPvy9",
        "outputId": "e8e30315-07c6-40ba-810a-a3358e45c279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Output: As a large language model, I am always working in the sense that I am continuously being trained and updated to better understand and respond to human language. I am not an individual, and I do not have a physical presence or the ability to take actions in the real world.\n",
            "\n",
            "I am developed by Google and designed to assist users with a wide range of language-related tasks, such as answering questions, providing information, generating text, and translating languages.\n",
            "\n",
            "May I help you with anything today?\n"
          ]
        }
      ],
      "source": [
        "#Test Gemini API\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure Gemini API Key\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "\n",
        "def test_gemini():\n",
        "    model = genai.GenerativeModel(\"gemini-pro\")\n",
        "    response = model.generate_content(\"Hello Gemini, are you working?\")\n",
        "    return response.text\n",
        "\n",
        "# Test the API\n",
        "try:\n",
        "    gemini_output = test_gemini()\n",
        "    print(\"Gemini Output:\", gemini_output)\n",
        "except Exception as e:\n",
        "    print(\"Gemini Error:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8g4SBTARbYU"
      },
      "source": [
        "## **5Ô∏è‚É£ Step 5: Generate Article Outline Using LLM1 (Groq Llama3)**  \n",
        "\n",
        "### **üîπ What is Happening in This Step?**  \n",
        "\n",
        "I am integrating **LLM1 (Groq Llama3-8B-8192)** to generate an article outline based on user input.  \n",
        "\n",
        "### **üîπ User Inputs:**  \n",
        "- **üìå Title:** The user enters the article title.  \n",
        "- **üìå Description (Optional):** A short description of the article.  \n",
        "- **üìå Word Count:** Defines the desired length of the article.  \n",
        "- **üìå Generate Button:** Click to create the structure.  \n",
        "\n",
        "### **üîπ Process Overview:**  \n",
        "1Ô∏è‚É£ The user enters the required inputs.  \n",
        "2Ô∏è‚É£ A structured **prompt** is created for LLM1.  \n",
        "3Ô∏è‚É£ The request is sent to **Groq‚Äôs API** for processing.  \n",
        "4Ô∏è‚É£ The model returns an **outline**, including:  \n",
        "   - **Introduction**  \n",
        "   - **3-5 Main Sections**  \n",
        "   - **Conclusion**  \n",
        "5Ô∏è‚É£ The generated outline is displayed in a **read-only text area**.  \n",
        "\n",
        "### **üîπ Error Handling:**  \n",
        "- **‚ö†Ô∏è If no title is entered, a warning is displayed.**  \n",
        "- **‚ö†Ô∏è If the API request fails, an error message is shown.**  \n",
        "\n",
        "üöÄ **Click the \"Generate Structure\" button to create an outline using LLM1!**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444,
          "referenced_widgets": [
            "b2b5f1853c934d3f8c7cceaa3291ae9a",
            "95270b4bcc9c40b0939711ace99482c6",
            "6388fcf6054e43829a2c90172aa81cb7",
            "6fb6a7466fdb4aaf8e90c7cecc800fa6",
            "993cae1218be4ab38b653030a2ea8329",
            "b7e8739684b9434b89356014d69e0880",
            "93b652fbcab146849892407dce7cbb7e",
            "15dd4fcc4ba041cdbef86ce76efb1c9c",
            "18a1ecd9346842ef94e9c87f5e12b759",
            "ecb2d92e3ce74a54a3a2be8d432d2f47",
            "562049c199594c9b860fd7c7b3c83767",
            "6207b95a88ef4cd1840bb6fcce001c92",
            "14f9bce69d8345d4acc3d47ee539cc1d",
            "043c3ebe091b4fa095cc29276486d9ad",
            "cb1531a35fd04d689faab0bc7a37feb0"
          ]
        },
        "id": "pEFc_mJ8RcUo",
        "outputId": "8d69c8a0-d9b3-443c-991c-d329aeff1115"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Title:', layout=Layout(height='50px', width='100%'), placeholder='Enter the ar‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2b5f1853c934d3f8c7cceaa3291ae9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Description:', layout=Layout(height='100px', width='100%'), placeholder='(Opti‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fb6a7466fdb4aaf8e90c7cecc800fa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntText(value=500, description='Word Count:')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93b652fbcab146849892407dce7cbb7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='primary', description='Generate Structure', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecb2d92e3ce74a54a3a2be8d432d2f47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Structure:', disabled=True, layout=Layout(height='150px', width='100%'), place‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14f9bce69d8345d4acc3d47ee539cc1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ **Generating article structure...**\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# üîπ User Inputs\n",
        "title_input = widgets.Textarea(\n",
        "    placeholder=\"Enter the article title...\",\n",
        "    description=\"Title:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"50px\")\n",
        ")\n",
        "\n",
        "description_input = widgets.Textarea(\n",
        "    placeholder=\"(Optional) Enter a short article description...\",\n",
        "    description=\"Description:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"100px\")\n",
        ")\n",
        "\n",
        "word_count_input = widgets.IntText(\n",
        "    description=\"Word Count:\",\n",
        "    value=500\n",
        ")\n",
        "\n",
        "generate_structure_button = widgets.Button(description=\"Generate Structure\", button_style='primary')\n",
        "\n",
        "# Display Inputs\n",
        "display(title_input, description_input, word_count_input, generate_structure_button)\n",
        "\n",
        "# üîπ Shared Output Widgets\n",
        "structure_text = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Generated structure will appear here...\",\n",
        "    description=\"Structure:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"150px\"),\n",
        "    disabled=True\n",
        ")\n",
        "display(structure_text)\n",
        "\n",
        "# üîπ API Keys & Model Details\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "GROQ_MODEL = \"llama3-8b-8192\"\n",
        "GROQ_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "# üîπ Function to Generate Structure\n",
        "def generate_article_structure(title, description, word_count):\n",
        "    \"\"\"Use Groq (Llama3) to generate an article structure.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Create a structured outline for an article with the following details:\n",
        "\n",
        "    Title: {title}\n",
        "    Description: {description if description else \"N/A\"}\n",
        "    Word Count: {word_count}\n",
        "\n",
        "    The outline should include:\n",
        "    - Introduction\n",
        "    - 3-5 main sections based on the topic\n",
        "    - Conclusion\n",
        "\n",
        "    Keep it detailed but concise.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {os.getenv('GROQ_API_KEY')}\"}\n",
        "    data = {\n",
        "        \"model\": GROQ_MODEL,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "\n",
        "    response = requests.post(GROQ_API_URL, json=data, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return f\"Error: {response.json()}\"\n",
        "\n",
        "# üîπ Handle Button Click\n",
        "def on_generate_structure(b):\n",
        "    title = title_input.value.strip()\n",
        "    description = description_input.value.strip()\n",
        "    word_count = word_count_input.value\n",
        "\n",
        "    if not title:\n",
        "        print(\"\\n‚ö†Ô∏è **Please enter a title!**\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüîπ **Generating article structure...**\")\n",
        "    structure = generate_article_structure(title, description, word_count)\n",
        "\n",
        "    structure_text.value = structure  # ‚úÖ Store in shared widget\n",
        "\n",
        "# üîπ Attach Button Click\n",
        "generate_structure_button.on_click(on_generate_structure)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9xfzpX2R0WH"
      },
      "source": [
        "## **6Ô∏è‚É£ Step 6: Critique Article Structure Using LLM2 (Mistral-Tiny)**  \n",
        "\n",
        "### **üîπ What is Happening in This Step?**  \n",
        "\n",
        "I am integrating **LLM2 (Mistral-Tiny)** to **critique the generated article structure** and provide **constructive feedback**.  \n",
        "\n",
        "### **üîπ User Interaction:**  \n",
        "- **üìå Critique Button:** Click to analyze the structure.  \n",
        "- **üìå Input:** The previously generated article outline.  \n",
        "\n",
        "### **üîπ Process Overview:**  \n",
        "1Ô∏è‚É£ The user clicks the **\"Critique Structure\"** button.  \n",
        "2Ô∏è‚É£ A structured **prompt** is sent to **LLM2 (Mistral-Tiny)**.  \n",
        "3Ô∏è‚É£ The model provides a **detailed review**, covering:  \n",
        "   - **Strengths of the structure**  \n",
        "   - **Missing important points**  \n",
        "   - **Suggestions for better organization**  \n",
        "4Ô∏è‚É£ The critique is displayed as text output.  \n",
        "\n",
        "### **üîπ Error Handling:**  \n",
        "- **‚ö†Ô∏è If no structure is available, a warning message is displayed.**  \n",
        "- **‚ö†Ô∏è If the API request fails, an error message is shown.**  \n",
        "\n",
        "üöÄ **Click the \"Critique Structure\" button to get feedback from LLM2!**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "171194b52a9c40f5b0ed81721b57371b",
            "ac80b230d64c48949dc7345fe1dbabff",
            "6ffb032d2bf644f89c75ef9839770aea"
          ]
        },
        "id": "-dA_vs8XR2ut",
        "outputId": "4cb672a5-59c4-47a5-b011-0c2c490c73ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='info', description='Critique Structure', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "171194b52a9c40f5b0ed81721b57371b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ **Critiquing article structure...**\n",
            "\n",
            "üìå **Mistral's Feedback:**\n",
            " The structure of the article \"Large Language Models\" is well-organized and provides a clear path for the reader, covering the topic comprehensively. Here are some suggestions for improvement and additional points to consider:\n",
            "\n",
            "Strengths:\n",
            "1. The article starts with an introduction that sets the context and provides a thesis statement, which is essential for guiding the reader through the article.\n",
            "2. The structure logically progresses from defining large language models (LLMs) to their applications, challenges, and concluding thoughts, making it easy to follow.\n",
            "3. The inclusion of various types of language models and their characteristics is a strong point, as it provides a more nuanced understanding of the topic.\n",
            "\n",
            "Missing Important Points:\n",
            "1. Consider adding a section discussing the training data used in LLMs, as this plays a significant role in their performance and potential biases.\n",
            "2. Discussing ethical considerations in the use of LLMs, such as privacy and security concerns, would be an important addition.\n",
            "3. In the \"Applications of Large Language Models\" section, you might want to include a brief mention of their use in creative writing, entertainment, and education.\n",
            "\n",
            "Suggestions for Better Organization:\n",
            "1. The \"Challenges and Limitations\" section could benefit from more specific examples of biases and errors in LLMs, along with potential solutions.\n",
            "2. Consider rearranging the \"Natural Language Processing (NLP)\" and \"Text generation and summarization\" subtopics within the \"Applications\" section, as they seem closely related.\n",
            "\n",
            "Overall, the structure is strong and covers the essential aspects of LLMs. Adding the missing points and reorganizing some sections can further improve the article's quality and comprehensiveness.\n"
          ]
        }
      ],
      "source": [
        "critique_button = widgets.Button(description=\"Critique Structure\", button_style='info')\n",
        "\n",
        "# Display Critique Button\n",
        "display(critique_button)\n",
        "\n",
        "# üîπ API Keys & Model Details\n",
        "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
        "MISTRAL_MODEL = \"mistral-tiny\"\n",
        "MISTRAL_API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "\n",
        "# üîπ Function to Get Mistral's Critique\n",
        "def critique_structure(structure):\n",
        "    \"\"\"Use Mistral to critique the generated structure.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert editor. Review the following article structure and provide constructive feedback:\n",
        "\n",
        "    Structure:\n",
        "    {structure}\n",
        "\n",
        "    Your critique should include:\n",
        "    - Strengths of the structure\n",
        "    - Any missing important points\n",
        "    - Suggestions for better organization\n",
        "    - Keep it professional and clear.\n",
        "    \"\"\"\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {os.getenv('MISTRAL_API_KEY')}\"}\n",
        "    data = {\n",
        "        \"model\": MISTRAL_MODEL,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "\n",
        "    response = requests.post(MISTRAL_API_URL, json=data, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return f\"Error: {response.json()}\"\n",
        "\n",
        "# üîπ Function to Trigger Critique\n",
        "def on_critique_structure(b):\n",
        "    structure = structure_text.value.strip()\n",
        "    if not structure:\n",
        "        print(\"\\n‚ö†Ô∏è **Please generate the structure first before critiquing!**\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüîπ **Critiquing article structure...**\")\n",
        "    critique = critique_structure(structure)\n",
        "    print(\"\\nüìå **Mistral's Feedback:**\\n\", critique)\n",
        "\n",
        "# üîπ Attach Button Click\n",
        "critique_button.on_click(on_critique_structure)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReuYbF-iWCtV"
      },
      "source": [
        "## **7Ô∏è‚É£ Step 7: Rewrite Article Structure Using LLM1 (Groq Llama3)**  \n",
        "\n",
        "### **üîπ What is Happening in This Step?**  \n",
        "\n",
        "I am using **LLM1 (Groq Llama3)** to **rewrite the article structure** based on **feedback from LLM2 (Mistral-Tiny)**.  \n",
        "\n",
        "### **üîπ User Interaction:**  \n",
        "- **üìå Rewrite Button:** Click to generate an improved version of the structure.  \n",
        "- **üìå Input:** The initial article structure and Mistral's critique.  \n",
        "\n",
        "### **üîπ Process Overview:**  \n",
        "1Ô∏è‚É£ The user clicks the **\"Rewrite Structure\"** button.  \n",
        "2Ô∏è‚É£ The **original structure** and **critique** are sent to **LLM1 (Groq Llama3)**.  \n",
        "3Ô∏è‚É£ The model revises the structure, ensuring:  \n",
        "   - **Better logical organization**  \n",
        "   - **Improved flow and clarity**  \n",
        "   - **Stronger alignment with critique suggestions**  \n",
        "4Ô∏è‚É£ The **rewritten structure** is displayed in the output widget.  \n",
        "\n",
        "### **üîπ Error Handling:**  \n",
        "- **‚ö†Ô∏è If the structure is missing, a warning is displayed.**  \n",
        "- **‚ö†Ô∏è If the critique is unavailable, the rewrite does not proceed.**  \n",
        "- **‚ö†Ô∏è If the API request fails, an error message is shown.**  \n",
        "\n",
        "üöÄ **Click the \"Rewrite Structure\" button to refine the article outline using LLM1!**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850,
          "referenced_widgets": [
            "910851ac39c049b182cb17d13cdd85b1",
            "671ac7f95b6d423dba17bbc23d1ea683",
            "f4d3e576de704d90813f17dd1527e5e8"
          ]
        },
        "id": "nliSJOBC_-jK",
        "outputId": "aaf645cf-37ee-4c84-eb6d-03b953495f56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='Rewrite Structure', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "910851ac39c049b182cb17d13cdd85b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ **Rewriting article structure...**\n",
            "\n",
            "‚úÖ **Rewritten Structure:**\n",
            " Here is a revised version of the article structure based on the critique:\n",
            "\n",
            "**I. Introduction (approx. 100 words)**\n",
            "\n",
            "* Brief overview of the topic: large language models (LLMs) and their significance in modern technology\n",
            "* Thesis statement: This article will delve into the concept of large language models, exploring their capabilities, applications, and limitations in various fields.\n",
            "\n",
            "**II. The Evolution of Language Models (approx. 150 words)**\n",
            "\n",
            "* Historical context: language models and their development over time\n",
            "* Types of language models: neural networks, recurrent neural networks, and their key characteristics\n",
            "* Key milestones in the development of LLMs\n",
            "\n",
            "**III. Applications of Large Language Models (approx. 350 words)**\n",
            "\n",
            "* Natural Language Processing (NLP) and its applications: chatbots, sentiment analysis, language translation, and more\n",
            "* Text generation and summarization: generating human-like text and condensing complex information\n",
            "* Question answering and knowledge retrieval: answering questions and retrieving information\n",
            "* Potential applications in industries: customer service, marketing, healthcare, and more\n",
            "\n",
            "**IV. Challenges and Limitations of Large Language Models (approx. 200 words)**\n",
            "\n",
            "* Biases and errors in LLMs: sources of bias and potential errors\n",
            "* Lack of understanding and transparency in LLMs: limitations in understanding how LLMs work and the potential consequences\n",
            "* Potential risks and consequences of relying on LLMs: job displacement, misinformation, and more\n",
            "* Future directions for improving LLMs: addressing biases, increasing transparency, and more\n",
            "\n",
            "**V. Conclusion (approx. 100 words)**\n",
            "\n",
            "* Summary of the main points: LLM capabilities, applications, and limitations\n",
            "* Future outlook for LLMs and their potential impact on society\n",
            "* Final thoughts on the importance of understanding and utilizing LLMs responsibly.\n",
            "\n",
            "Total word count: 1000 words.\n",
            "\n",
            "Changes made:\n",
            "\n",
            "* Reorganized the structure to improve logical flow and clarity\n",
            "* Added more specific details and examples to support key points\n",
            "* Increased word count for section IV to provide more comprehensive coverage of challenges and limitations\n",
            "* Emphasized the importance of understanding and utilizing LLMs responsibly in the conclusion\n"
          ]
        }
      ],
      "source": [
        "rewrite_button = widgets.Button(description=\"Rewrite Structure\", button_style='success')\n",
        "\n",
        "# Display Rewrite Button\n",
        "display(rewrite_button)\n",
        "\n",
        "# üîπ Function to Rewrite Structure\n",
        "def rewrite_structure(structure, critique):\n",
        "    \"\"\"Use Groq (Llama3) to rewrite the article structure based on Mistral's critique.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Revise the article structure based on this critique:\n",
        "\n",
        "    Structure:\n",
        "    {structure}\n",
        "\n",
        "    Critique:\n",
        "    {critique}\n",
        "\n",
        "    Ensure that the revised version is logically organized and improved based on feedback.\n",
        "    \"\"\"\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {os.getenv('GROQ_API_KEY')}\"}\n",
        "    data = {\n",
        "        \"model\": GROQ_MODEL,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "\n",
        "    response = requests.post(GROQ_API_URL, json=data, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return f\"Error: {response.json()}\"\n",
        "\n",
        "# üîπ Function to Handle Rewrite\n",
        "def on_rewrite_structure(b):\n",
        "    structure = structure_text.value.strip()\n",
        "    critique = structure_text.value.strip()\n",
        "\n",
        "    if not structure or not critique:\n",
        "        print(\"\\n‚ö†Ô∏è **Please generate and critique the structure before rewriting!**\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüîπ **Rewriting article structure...**\")\n",
        "    rewritten_structure = rewrite_structure(structure, critique)\n",
        "    structure_text.value = rewritten_structure\n",
        "    print(\"\\n‚úÖ **Rewritten Structure:**\\n\", rewritten_structure)\n",
        "\n",
        "# üîπ Attach Button Click\n",
        "rewrite_button.on_click(on_rewrite_structure)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtfPVW9qpSSz"
      },
      "source": [
        "## **8Ô∏è‚É£ Step 8: Final Critique Using LLM2 (Mistral)**  \n",
        "\n",
        "### **üîπ What is Happening in This Step?**  \n",
        "\n",
        "I am using **LLM2 (Mistral-Tiny)** to **critique the improved article structure**, which was rewritten by **LLM1 (Groq Llama3)** in the previous step.  \n",
        "\n",
        "### **üîπ User Interaction:**  \n",
        "- **üìå Final Critique Button:** Click to get **Mistral‚Äôs** final feedback on the revised structure.  \n",
        "- **üìå Input:** The rewritten structure from LLM1 (Groq Llama3).  \n",
        "\n",
        "### **üîπ Process Overview:**  \n",
        "1Ô∏è‚É£ The user clicks the **\"Final Critique\"** button.  \n",
        "2Ô∏è‚É£ The **rewritten article structure** is sent to **LLM2 (Mistral-Tiny)**.  \n",
        "3Ô∏è‚É£ Mistral evaluates the structure and provides:  \n",
        "   - **Any remaining structural weaknesses**  \n",
        "   - **Suggestions for better clarity and organization**  \n",
        "   - **Final refinements to enhance readability**  \n",
        "4Ô∏è‚É£ The **final critique** is displayed in the output widget.  \n",
        "\n",
        "### **üîπ Error Handling:**  \n",
        "- **‚ö†Ô∏è If the rewritten structure is missing, a warning is displayed.**  \n",
        "- **‚ö†Ô∏è If the API request fails, an error message is shown.**  \n",
        "\n",
        "üöÄ **Click the \"Final Critique\" button to refine the structure with expert-level feedback from LLM2!**  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "b62fb54fef76434babb662a9d98bdb18",
            "1b6043958e3548d6a514bdd84f277bb9",
            "8d58905f45e84a94b19cd2a0ebc24aed"
          ]
        },
        "id": "ZTx63nFvsHMn",
        "outputId": "4ad00ded-fad3-4d2b-99d5-93a0e230fdff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='warning', description='Final Critique', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b62fb54fef76434babb662a9d98bdb18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ **Performing final critique on the rewritten structure...**\n",
            "\n",
            "üìå **Final Critique from Mistral:**\n",
            " Overall, the revised article structure is well-organized and covers the key aspects of large language models (LLMs) effectively. However, there are a few areas for further improvement to ensure a coherent and engaging read for the audience. Here are my suggestions:\n",
            "\n",
            "1. **Introduction (approx. 100 words)**\n",
            "   - While the introduction briefly introduces the topic, it could benefit from setting the stage by discussing the potential impact of LLMs on modern society or highlighting a specific challenge or opportunity they present. This will help engage the reader and provide context for the rest of the article.\n",
            "\n",
            "2. **The Evolution of Language Models (approx. 150 words)**\n",
            "   - This section provides a good historical context and explains the types of language models. However, it would be beneficial to include more specific examples of how these models have evolved and how they differ from earlier language processing techniques.\n",
            "\n",
            "3. **Applications of Large Language Models (approx. 350 words)**\n",
            "   - This section is well-written and covers a range of applications. However, it might be helpful to include more recent developments or examples to demonstrate the current state and potential of LLMs. Also, consider adding a subsection to discuss ethical considerations in the use of LLMs in these applications.\n",
            "\n",
            "4. **Challenges and Limitations of Large Language Models (approx. 200 words)**\n",
            "   - This section does a good job of highlighting the challenges and limitations of LLMs. However, it could benefit from more concrete examples of how these issues have manifested in real-world applications.\n",
            "\n",
            "5. **Conclusion (approx. 100 words)**\n",
            "   - The conclusion effectively summarizes the main points. To strengthen it, consider including a call to action or a thought-provoking question to encourage further discussion and engagement with the topic.\n",
            "\n",
            "6. **Transitions between sections**\n",
            "   - While the transitions between sections are generally smooth, it might be beneficial to include more explicit connections between the different parts of the article. This will help guide the reader through the text and ensure that the various sections build upon each other effectively.\n"
          ]
        }
      ],
      "source": [
        "# üîπ Critique Button for Rewritten Structure\n",
        "final_critique_button = widgets.Button(description=\"Final Critique\", button_style='warning')\n",
        "\n",
        "# Display Final Critique Button\n",
        "display(final_critique_button)\n",
        "\n",
        "# üîπ Function for LLM2 to Critique Rewritten Structure\n",
        "def final_critique_structure(rewritten_structure):\n",
        "    \"\"\"Use Mistral to critique the improved structure from LLM1.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert editor. Review the following revised article structure and provide a final critique:\n",
        "\n",
        "    Revised Structure:\n",
        "    {rewritten_structure}\n",
        "\n",
        "    Provide constructive feedback, pointing out:\n",
        "    - Any remaining structural weaknesses\n",
        "    - Areas for further improvement\n",
        "    - Suggestions for better flow and clarity\n",
        "    - Keep it professional and actionable.\n",
        "    \"\"\"\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {os.getenv('MISTRAL_API_KEY')}\"}\n",
        "    data = {\n",
        "        \"model\": MISTRAL_MODEL,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "\n",
        "    response = requests.post(MISTRAL_API_URL, json=data, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return f\"Error: {response.json()}\"\n",
        "\n",
        "# üîπ Function to Handle Final Critique\n",
        "def on_final_critique(b):\n",
        "    rewritten_structure = structure_text.value.strip()\n",
        "\n",
        "    if not rewritten_structure:\n",
        "        print(\"\\n‚ö†Ô∏è **Please rewrite the structure before requesting a final critique!**\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüîπ **Performing final critique on the rewritten structure...**\")\n",
        "    final_critique = final_critique_structure(rewritten_structure)\n",
        "\n",
        "    print(\"\\nüìå **Final Critique from Mistral:**\\n\", final_critique)\n",
        "\n",
        "# üîπ Attach Button Click\n",
        "final_critique_button.on_click(on_final_critique)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcsSOfuHpYQ5"
      },
      "source": [
        "## **9Ô∏è‚É£ Step 9: Final Review & Refinement Using LLM1 (Groq Llama3)**  \n",
        "\n",
        "### **üîπ What is Happening in This Step?**  \n",
        "\n",
        "This is the **final optimization stage**, where **LLM1 (Groq Llama3)** refines the **rewritten article structure** based on the **final critique** given by **LLM2 (Mistral-Tiny).**  \n",
        "\n",
        "### **üîπ User Interaction:**  \n",
        "- **üìå Final Review Button:** Click to let **Groq Llama3** optimize the structure.  \n",
        "- **üìå Input:** The **rewritten structure** and the **final critique from Mistral**.  \n",
        "\n",
        "### **üîπ Process Overview:**  \n",
        "1Ô∏è‚É£ The user clicks the **\"Final Review\"** button.  \n",
        "2Ô∏è‚É£ The **latest rewritten structure** and **Mistral‚Äôs critique** are sent to **LLM1 (Groq Llama3).**  \n",
        "3Ô∏è‚É£ LLM1 performs:  \n",
        "   - **Final structural refinements**  \n",
        "   - **Ensures logical flow and clarity**  \n",
        "   - **Optimizes coherence for readability**  \n",
        "4Ô∏è‚É£ The **final reviewed structure** is displayed and updated.  \n",
        "\n",
        "### **üîπ Error Handling:**  \n",
        "- **‚ö†Ô∏è If the previous critique step is incomplete, a warning is shown.**  \n",
        "- **‚ö†Ô∏è If the API request fails, an error message is displayed.**  \n",
        "\n",
        "üöÄ **Click the \"Final Review\" button to generate the fully optimized structure!**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920,
          "referenced_widgets": [
            "eef4fe4631b1447e9cf24b618454156b",
            "f9025b971eeb4254b73c016f64291f1b",
            "2d8c263f10f44064a3e341e7af3eadfe"
          ]
        },
        "id": "C80x_pHVsiZ3",
        "outputId": "1c6c774f-969b-4aa6-ae4b-19a56bbb22a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='Final Review', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eef4fe4631b1447e9cf24b618454156b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ **Performing final review and refining structure...**\n",
            "\n",
            "‚úÖ **Final Reviewed Structure:**\n",
            " Based on the final critique, I will revise the article structure to improve its logical flow, clarity, and coherence. Here is the revised structure:\n",
            "\n",
            "**I. Introduction (approx. 100 words)**\n",
            "\n",
            "* A surprising fact about the rapid development of large language models (LLMs): \"Did you know that LLMs have evolved from simple chatbots to sophisticated language understanding systems in just a few years?\"\n",
            "* Brief overview of the topic: LLMs and their significance in modern technology\n",
            "* Thesis statement: This article will delve into the concept of large language models, exploring their capabilities, applications, and limitations in various fields.\n",
            "\n",
            "**II. The Evolution of Language Models (approx. 200 words)**\n",
            "\n",
            "* Historical context: language models and their development over time\n",
            "* Key figures and their contributions to the development of LLMs\n",
            "* Explanation of neural networks and recurrent neural networks (RNNs): \"In simple terms, neural networks are artificial intelligence systems that mimic the human brain, while RNNs are a type of neural network that can process sequential data, such as speech or text.\"\n",
            "* Key milestones in the development of LLMs\n",
            "\n",
            "**III. Applications of Large Language Models (approx. 350 words)**\n",
            "\n",
            "* Natural Language Processing (NLP) and its applications: chatbots, sentiment analysis, language translation, and more\n",
            "* Concrete examples of how LLMs are being used in real-world applications, including case studies or examples from well-known companies or industries\n",
            "* Discussion of the ethical implications of these applications\n",
            "\n",
            "**IV. Challenges and Limitations of Large Language Models (approx. 250 words)**\n",
            "\n",
            "* Specific examples of biases and errors in LLMs, including cases where LLMs have made mistakes or perpetuated biases\n",
            "* Explanation of the economic implications of LLMs, including potential job displacement and the cost of developing and maintaining LLMs\n",
            "* Discussion of the potential risks and consequences of relying on LLMs, such as misinformation and job displacement\n",
            "* Future directions for improving LLMs, including addressing biases, increasing transparency, and more\n",
            "\n",
            "**V. Conclusion (approx. 100 words)**\n",
            "\n",
            "* Summary of the main points: LLM capabilities, applications, and limitations\n",
            "* Discussion of the potential for LLMs to be used for positive social change, such as in education or accessibility for people with disabilities\n",
            "* Final thoughts on the importance of understanding and utilizing LLMs responsibly.\n",
            "\n",
            "Total word count: 1000 words.\n",
            "\n",
            "Changes made:\n",
            "\n",
            "* Added a surprising fact to the introduction to engage the reader\n",
            "* Expanded the historical context in section II to provide a better understanding of the development of LLMs\n",
            "* Added concrete examples to section III to illustrate the applications of LLMs\n",
            "* Increased the word count for section IV to provide more comprehensive coverage of challenges and limitations\n",
            "* Emphasized the potential for LLMs to be used for positive social change in the conclusion\n",
            "\n",
            "I hope this revised structure meets the requirements and is fully optimized with logical organization, clarity, and coherence.\n"
          ]
        }
      ],
      "source": [
        "# üîπ Button for LLM1's Final Review\n",
        "final_review_button = widgets.Button(description=\"Final Review\", button_style='success')\n",
        "\n",
        "# Display Final Review Button\n",
        "display(final_review_button)\n",
        "\n",
        "# üîπ Function for LLM1 to Review LLM2's Final Critique\n",
        "def final_review_structure(rewritten_structure, final_critique):\n",
        "    \"\"\"Use Groq (Llama3) to review and refine the article structure based on the final critique from LLM2.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Review and refine the article structure based on the following final critique:\n",
        "\n",
        "    Revised Structure:\n",
        "    {rewritten_structure}\n",
        "\n",
        "    Final Critique:\n",
        "    {final_critique}\n",
        "\n",
        "    Ensure the final version is fully optimized with logical organization, clarity, and coherence.\n",
        "    \"\"\"\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {os.getenv('GROQ_API_KEY')}\"}\n",
        "    data = {\n",
        "        \"model\": GROQ_MODEL,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "\n",
        "    response = requests.post(GROQ_API_URL, json=data, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return f\"Error: {response.json()}\"\n",
        "\n",
        "# üîπ Function to Handle LLM1's Final Review\n",
        "def on_final_review(b):\n",
        "    rewritten_structure = structure_text.value.strip()  # ‚úÖ Using latest rewritten structure\n",
        "    final_critique = final_critique_structure(rewritten_structure)  # ‚úÖ LLM2's second critique\n",
        "\n",
        "    if not rewritten_structure or not final_critique:\n",
        "        print(\"\\n‚ö†Ô∏è **Please complete the previous critique step before final review!**\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüîπ **Performing final review and refining structure...**\")\n",
        "    final_review = final_review_structure(rewritten_structure, final_critique)\n",
        "\n",
        "    structure_text.value = final_review  # ‚úÖ Updating structure with final review\n",
        "    print(\"\\n‚úÖ **Final Reviewed Structure:**\\n\", final_review)\n",
        "\n",
        "# üîπ Attach Button Click\n",
        "final_review_button.on_click(on_final_review)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGwpAa5HtCGH"
      },
      "source": [
        "## **üîü Step 10: Generate the Final Article Using LLM1 (Groq Llama3)**  \n",
        "\n",
        "### **üîπ What Happens in This Step?**  \n",
        "Now that the article structure is fully refined, we generate the complete article using **LLM1 (Groq Llama3).**  \n",
        "This step ensures the **final article is well-written, coherent, and follows the optimized structure.**  \n",
        "\n",
        "### **üîπ User Interaction:**  \n",
        "- **üìå Generate Article Button:** Click to create the final article.  \n",
        "- **üìå Input Fields:**  \n",
        "  - **Title** (Optional, defaults to *Final Generated Article*)  \n",
        "  - **Word Count** (Must be a valid number)  \n",
        "  - **Final Structure** (From the previous step)  \n",
        "\n",
        "### **üîπ Process Overview:**  \n",
        "1Ô∏è‚É£ The user clicks the **\"Generate Final Article\"** button.  \n",
        "2Ô∏è‚É£ The **final reviewed structure**, title, and word count are sent to **Groq Llama3.**  \n",
        "3Ô∏è‚É£ LLM1 generates a **full-length article** that:  \n",
        "   - **Maintains logical flow**  \n",
        "   - **Ensures clarity and coherence**  \n",
        "   - **Adheres to the provided structure**  \n",
        "4Ô∏è‚É£ The final article appears in the **text area** for user review.  \n",
        "\n",
        "### **üîπ Error Handling:**  \n",
        "- **‚ö†Ô∏è If the final structure is missing, a warning is shown.**  \n",
        "- **‚ö†Ô∏è If the word count is invalid, an error message appears.**  \n",
        "\n",
        "üöÄ **Click \"Generate Final Article\" to create the final polished content!**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a68345f23be4493188a7599955114d10",
            "9a24b7dec425410f8dbf63c8a7f9c58e",
            "f110ad2bc3614ccbb8c0c9e4eddac2f6",
            "020c874b304445eea17787399c8c44c0",
            "6f36a14d033f49d2a63cd068f0084e5f",
            "8457b51978bc440289aefe69d3833878"
          ]
        },
        "id": "GmxZA79tu05n",
        "outputId": "26b474a8-d535-4bf7-9292-f621abc8f12f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='primary', description='Generate Final Article', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a68345f23be4493188a7599955114d10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', layout=Layout(height='300px', width='100%'), placeholder='Generated article will appear her‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "020c874b304445eea17787399c8c44c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ **Generating final article...**\n",
            "\n",
            "‚úÖ **Final Generated Article:**\n",
            " **Large Language Models: A New Era in Artificial Intelligence**\n",
            "\n",
            "Did you know that large language models (LLMs) have evolved from simple chatbots to sophisticated language understanding systems in just a few years? This rapid development has transformed the way we interact with technology, enabling applications that were previously unimaginable. In this article, we will delve into the concept of large language models, exploring their capabilities, applications, and limitations in various fields.\n",
            "\n",
            "**The Evolution of Language Models**\n",
            "\n",
            "The concept of language models dates back to the 1960s, when the first chatbots were developed. However, it wasn't until the 2010s that LLMs began to take shape. Key figures such as Geoffrey Hinton, Yann LeCun, and Yoshua Bengio made significant contributions to the development of LLMs. Neural networks, a type of artificial intelligence system that mimics the human brain, were a crucial component in the development of LLMs. Recurrent neural networks (RNNs), in particular, allowed LLMs to process sequential data, such as speech or text.\n",
            "\n",
            "The development of LLMs accelerated in the 2010s, with milestones such as the introduction of the Word2Vec algorithm in 2013 and the development of the Transformer model in 2017. Today, LLMs are being used in a wide range of applications, from customer service chatbots to medical diagnosis.\n",
            "\n",
            "**Applications of Large Language Models**\n",
            "\n",
            "LLMs have numerous applications in the field of Natural Language Processing (NLP). One of the most significant applications is in chatbots, which use LLMs to understand and respond to user queries. LLMs are also being used in sentiment analysis, language translation, and text summarization.\n",
            "\n",
            "Concrete examples of LLM applications can be seen in industries such as healthcare and finance. For instance, IBM's Watson for Oncology uses LLMs to analyze patient data and provide personalized treatment options. Similarly, banks such as JPMorgan Chase are using LLMs to analyze customer data and provide personalized financial advice.\n",
            "\n",
            "However, the applications of LLMs also raise ethical concerns. For instance, the use of LLMs in hiring processes has raised concerns about bias and discrimination. The use of LLMs in healthcare has also raised concerns about the potential for misdiagnosis and misinformation.\n",
            "\n",
            "**Challenges and Limitations of Large Language Models**\n",
            "\n",
            "Despite their many benefits, LLMs are not without their challenges and limitations. One of the most significant challenges is bias, which can be built into LLMs through the data used to train them. This bias can result in inaccurate or discriminatory outputs.\n",
            "\n",
            "Another challenge is the lack of transparency in LLMs. It can be difficult to understand how LLMs arrive at their outputs, which can make it challenging to identify and correct errors.\n",
            "\n",
            "The economic implications of LLMs are also significant. The development and maintenance of LLMs require significant resources, which can be a barrier to entry for smaller companies. Additionally, the use of LLMs can displace jobs, particularly in industries such as customer service and data entry.\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "Large language models have come a long way in a short amount of time, and their applications are vast and varied. However, it is essential to understand the challenges and limitations of LLMs and to approach their development and deployment with caution.\n",
            "\n",
            "Despite these challenges, LLMs have the potential to be used for positive social change. For instance, LLMs can be used to improve accessibility for people with disabilities, such as language translation software for sign language interpreters. LLMs can also be used to improve education, such as AI-powered tutors that can provide personalized learning recommendations.\n",
            "\n",
            "As we move forward with the development and deployment of LLMs, it is essential that we prioritize transparency, accountability, and ethics. By doing so, we can ensure that LLMs are used to benefit society, rather than to perpetuate biases and errors.\n",
            "\n",
            "**Total Word Count: 1000**\n"
          ]
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "# üîπ Button to Generate Final Article\n",
        "generate_final_article_button = widgets.Button(description=\"Generate Final Article\", button_style='primary')\n",
        "\n",
        "# Display Generate Article Button\n",
        "display(generate_final_article_button)\n",
        "\n",
        "# üîπ Function to Generate Final Article\n",
        "def generate_final_article(title, final_structure, word_count):\n",
        "    \"\"\"Use Groq (Llama3) to generate a full article based on the final reviewed structure with a title and word count.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Generate a complete, well-written article based on the following final structure.\n",
        "    The article must be approximately {word_count} words long.\n",
        "\n",
        "    **Title:** {title}\n",
        "\n",
        "    Final Structure:\n",
        "    {final_structure}\n",
        "\n",
        "    Ensure the article maintains coherence, clarity, and logical flow while following the structure.\n",
        "    At the end, include:\n",
        "    **Total Word Count: {word_count}**\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {os.getenv('GROQ_API_KEY')}\"}\n",
        "\n",
        "    data = {\n",
        "        \"model\": GROQ_MODEL,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "\n",
        "    response = requests.post(GROQ_API_URL, json=data, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return f\"Error: {response.json()}\"\n",
        "\n",
        "# üîπ Function to Handle Final Article Generation\n",
        "def on_generate_final_article(b):\n",
        "    title = title_input.value.strip()\n",
        "    final_reviewed_structure = structure_text.value.strip()  # ‚úÖ Using the final reviewed structure\n",
        "    word_count = str(word_count_input.value).strip()  # ‚úÖ Convert to string before stripping\n",
        "\n",
        "    # ‚úÖ Ensure title, final structure, and word count are provided\n",
        "    if not title:\n",
        "        title = \"Final Generated Article\"\n",
        "    if not final_reviewed_structure:\n",
        "        print(\"\\n‚ö†Ô∏è **Please complete the final review step before generating the article!**\")\n",
        "        return\n",
        "    if not word_count.isdigit():\n",
        "        print(\"\\n‚ö†Ô∏è **Please enter a valid number for word count!**\")\n",
        "        return\n",
        "\n",
        "    word_count = int(word_count)  # ‚úÖ Convert word count back to integer after validation\n",
        "\n",
        "    print(\"\\nüîπ **Generating final article...**\")\n",
        "    final_article = generate_final_article(title, final_reviewed_structure, word_count)\n",
        "\n",
        "    article_text.value = final_article  # ‚úÖ Save full article in text area\n",
        "    print(\"\\n‚úÖ **Final Generated Article:**\\n\", final_article)\n",
        "\n",
        "# üîπ Attach Button Click\n",
        "generate_final_article_button.on_click(on_generate_final_article)\n",
        "\n",
        "# üîπ Text Box to Show Generated Article\n",
        "article_text = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Generated article will appear here...\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"300px\")\n",
        ")\n",
        "\n",
        "display(article_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT8KL7c-Wnwx"
      },
      "source": [
        "## **‚ûä Step 11: Enhance the Article Using LLM2 (Gemini Pro)**  \n",
        "\n",
        "### **üîπ What Happens in This Step?**  \n",
        "After generating the **final article** using **Groq Llama3,** we use **LLM2 (Gemini Pro)** to refine and enhance it.  \n",
        "This step ensures that the article:  \n",
        "‚úÖ **Maintains clarity, coherence, and engagement**  \n",
        "‚úÖ **Preserves the structure and original meaning**  \n",
        "‚úÖ **Has improved flow and readability**  \n",
        "\n",
        "### **üîπ User Interaction:**  \n",
        "- **üìå Enhance with Gemini Button:** Click to refine the article.  \n",
        "- **üìå Input Fields:**  \n",
        "  - **Title** (Optional, defaults to *Enhanced Article*)  \n",
        "  - **Word Count** (Valid number required)  \n",
        "  - **Original Article** (From the previous step)  \n",
        "\n",
        "### **üîπ Process Overview:**  \n",
        "1Ô∏è‚É£ The user clicks **\"Enhance with Gemini\"** to start the enhancement.  \n",
        "2Ô∏è‚É£ The **original article** (from Groq) is sent to **Gemini Pro** for improvement.  \n",
        "3Ô∏è‚É£ LLM2 enhances the article while:  \n",
        "   - **Keeping the word count approximately the same**  \n",
        "   - **Ensuring better readability and engagement**  \n",
        "   - **Maintaining logical flow and structure**  \n",
        "4Ô∏è‚É£ The **enhanced article** appears in the text area for final review.  \n",
        "\n",
        "### **üîπ Error Handling:**  \n",
        "- **‚ö†Ô∏è If the original article is missing, a warning appears.**  \n",
        "- **‚ö†Ô∏è If the word count is invalid, an error message is shown.**  \n",
        "\n",
        "üöÄ **Click \"Enhance with Gemini\" to refine and perfect the article!**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f4207deddbce42cdb6d24b806c9fac5d",
            "d8e9b255deaf4ef79d1992baf9ea74f4",
            "b0fc2f9ea87449888e31967bf57af6d0",
            "ddb4ac0cf9bd4f418c40f803ab8b37f5",
            "26fc96eb60e94f549293d6b6afaa1bb0",
            "30c7c3fedb6c4da29eb6bddd0d369c88"
          ]
        },
        "id": "xLf_boyNBihB",
        "outputId": "b3776884-46d6-428d-827b-80e5fe629309"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='Enhance with Gemini', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4207deddbce42cdb6d24b806c9fac5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', layout=Layout(height='300px', width='100%'), placeholder='Enhanced article will appear here‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddb4ac0cf9bd4f418c40f803ab8b37f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ **Enhancing article using Gemini...**\n",
            "\n",
            "‚úÖ **Enhanced Article:**\n",
            " **Title:** The Rise of Large Language Models: Ushering in a New Era of Language Technology\n",
            "\n",
            "In an era where technology advances at an unprecedented pace, large language models (LLMs) have emerged as a transformative force in artificial intelligence (AI). Their rapid evolution has pushed the boundaries of language understanding, paving the way for countless applications that were once deemed impossible.\n",
            "\n",
            "**The Dawn of Language Models**\n",
            "\n",
            "The concept of language models has its roots in the 1960s, with the advent of simple chatbots. However, it wasn't until the 2010s that LLMs truly blossomed. Visionaries like Geoffrey Hinton, Yann LeCun, and Yoshua Bengio laid the foundation for their development.\n",
            "\n",
            "Neural networks, inspired by the intricacies of the human brain, became instrumental in the creation of LLMs. Recurrent neural networks (RNNs), in particular, empowered LLMs to unravel the intricate sequences of spoken or written language.\n",
            "\n",
            "**LLMs: A Quantum Leap in NLP**\n",
            "\n",
            "The development of LLMs accelerated dramatically in the 2010s. Milestones like the Word2Vec algorithm in 2013 and the revolutionary Transformer model in 2017 propelled LLMs into the limelight. Today, they are deployed in a diverse array of applications, from conversational chatbots to life-saving medical diagnoses.\n",
            "\n",
            "LLMs have become a game-changer in the realm of Natural Language Processing (NLP). Seamlessly understanding and responding to user inquiries, chatbots powered by LLMs are revolutionizing customer service. Moreover, LLMs excel in sentiment analysis, language translation, and text summarization, making language barriers a thing of the past.\n",
            "\n",
            "Real-world examples of LLM applications abound. IBM's Watson for Oncology harnesses the power of LLMs to unravel patient data, delivering personalized treatment plans. Leading banks like JPMorgan Chase leverage LLMs to decipher customer data, offering tailored financial guidance.\n",
            "\n",
            "**Challenges and Ethical Considerations**\n",
            "\n",
            "While LLMs offer tremendous potential, they are not immune to challenges and ethical dilemmas. Bias is an inherent concern, as LLMs can inherit biases from the data they are trained on. This can lead to skewed or discriminatory outcomes.\n",
            "\n",
            "Transparency is another crucial consideration. It can be challenging to decipher how LLMs arrive at their conclusions, hindering error detection and correction.\n",
            "\n",
            "Furthermore, the economic impact of LLMs cannot be overlooked. Their development and upkeep require substantial resources, potentially limiting access for smaller businesses. Additionally, the widespread use of LLMs could displace jobs in sectors like customer service and data entry.\n",
            "\n",
            "**Unlocking the Future with LLMs**\n",
            "\n",
            "Despite these challenges, LLMs possess immense promise for positive social change. They can enhance accessibility for those with disabilities, providing sign language translation for deaf individuals. Furthermore, they can revolutionize education, offering personalized learning recommendations through AI-powered tutors.\n",
            "\n",
            "As we continue to explore the boundless possibilities of LLMs, it is paramount to prioritize transparency, accountability, and ethical considerations. By forging a path that upholds these principles, we can harness the power of LLMs to uplift society, bridging knowledge gaps and fostering progress.\n",
            "\n",
            "**Total Word Count: 1000**\n"
          ]
        }
      ],
      "source": [
        "# üîπ Define Gemini API URL\n",
        "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\"\n",
        "\n",
        "# üîπ Button to Enhance Article Using Gemini\n",
        "enhance_article_button = widgets.Button(description=\"Enhance with Gemini\", button_style='success')\n",
        "\n",
        "# Display Button\n",
        "display(enhance_article_button)\n",
        "\n",
        "# üîπ Function to Enhance Article Using Gemini\n",
        "def enhance_article_with_gemini(title, generated_article, word_count):\n",
        "    \"\"\"Use Gemini API to enhance the article generated by Groq.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Improve the following article while keeping the same meaning, structure, and length.\n",
        "    Make it more engaging, coherent, and well-written.\n",
        "\n",
        "    **Title:** {title}\n",
        "\n",
        "    **Original Article:**\n",
        "    {generated_article}\n",
        "\n",
        "    **Enhance it but maintain approximately {word_count} words.**\n",
        "    At the end, include:\n",
        "    **Total Word Count: {word_count}**\n",
        "    \"\"\"\n",
        "\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    params = {\"key\": GEMINI_API_KEY}\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "\n",
        "    response = requests.post(GEMINI_API_URL, json=data, headers=headers, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "    else:\n",
        "        return f\"Error: {response.json()}\"\n",
        "\n",
        "# üîπ Function to Handle Article Enhancement\n",
        "def on_enhance_article(b):\n",
        "    title = title_input.value.strip()\n",
        "    generated_article = article_text.value.strip()  # ‚úÖ Use the article generated by Groq\n",
        "    word_count = str(word_count_input.value).strip()\n",
        "\n",
        "    if not title:\n",
        "        title = \"Enhanced Article\"\n",
        "    if not generated_article:\n",
        "        print(\"\\n‚ö†Ô∏è **Please generate the article first before enhancing!**\")\n",
        "        return\n",
        "    if not word_count.isdigit():\n",
        "        print(\"\\n‚ö†Ô∏è **Please enter a valid number for word count!**\")\n",
        "        return\n",
        "\n",
        "    word_count = int(word_count)\n",
        "\n",
        "    print(\"\\nüîπ **Enhancing article using Gemini...**\")\n",
        "    enhanced_article = enhance_article_with_gemini(title, generated_article, word_count)\n",
        "\n",
        "    enhanced_article_text.value = enhanced_article\n",
        "    print(\"\\n‚úÖ **Enhanced Article:**\\n\", enhanced_article)\n",
        "\n",
        "# üîπ Attach Button Click\n",
        "enhance_article_button.on_click(on_enhance_article)\n",
        "\n",
        "# üîπ Text Box to Show Enhanced Article\n",
        "enhanced_article_text = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Enhanced article will appear here...\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"300px\")\n",
        ")\n",
        "\n",
        "display(enhanced_article_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqbzJM9qCOGh"
      },
      "source": [
        "<!-- Step 12: Save the Article in TXT, PDF, or DOCX -->\n",
        "  \n",
        "## **‚ûä  Step 12: Save the Article in TXT, PDF, or DOCX**\n",
        "\n",
        "\n",
        "  <p><strong>üîπ What Happens in This Step?</strong><br>\n",
        "  After refining the article with <strong>Gemini Pro</strong>, you can save it in different formats for easy sharing and access.<br>\n",
        "  This step allows you to save the article as:</p>\n",
        "\n",
        "  <ul>\n",
        "    <li>‚úÖ <strong>Plain text (TXT)</strong> ‚Äì Simple and lightweight</li>\n",
        "    <li>‚úÖ <strong>PDF</strong> ‚Äì Professionally formatted with proper layout</li>\n",
        "    <li>‚úÖ <strong>DOCX</strong> ‚Äì Editable format for further modifications</li>\n",
        "  </ul>\n",
        "\n",
        "  <p><strong>üîπ User Interaction:</strong></p>\n",
        "  <ul>\n",
        "    <li>üìå <strong>Article Selection Dropdown:</strong> Choose between:\n",
        "      <ul>\n",
        "        <li><strong>LL1 Full Article</strong> (Original article from Groq Llama3)</li>\n",
        "        <li><strong>Gemini Enhanced Article</strong> (Improved version)</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "    <li>üìå <strong>Format Selection Dropdown:</strong> Choose to save as <strong>TXT, PDF, or DOCX.</strong></li>\n",
        "    <li>üìå <strong>Save Button:</strong> Click to save the article.</li>\n",
        "  </ul>\n",
        "\n",
        "  <p><strong>üîπ Process Overview:</strong></p>\n",
        "  <ol>\n",
        "    <li>The user selects the <strong>article type</strong> (LL1 or Gemini Enhanced).</li>\n",
        "    <li>The user selects the <strong>file format</strong> (TXT, PDF, DOCX).</li>\n",
        "    <li>Clicking <strong>\"Save Article\"</strong> triggers the formatting and saving process.</li>\n",
        "    <li>The article is formatted based on the selected format:\n",
        "      <ul>\n",
        "        <li><strong>TXT:</strong> Saves as a simple text file.</li>\n",
        "        <li><strong>PDF:</strong> Applies <strong>structured formatting</strong>, including:\n",
        "          <ul>\n",
        "            <li>Proper <strong>title styling</strong></li>\n",
        "            <li><strong>Bold subheadings</strong></li>\n",
        "            <li><strong>Bullet point formatting</strong></li>\n",
        "            <li><strong>Justified text for readability</strong></li>\n",
        "            <li><strong>Word count display</strong></li>\n",
        "          </ul>\n",
        "        </li>\n",
        "        <li><strong>DOCX:</strong> Saves in an editable format for further customization.</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "    <li>A success message confirms the article has been saved.</li>\n",
        "  </ol>\n",
        "\n",
        "  <p><strong>üîπ Error Handling:</strong></p>\n",
        "  <ul>\n",
        "    <li>‚ö†Ô∏è If no article content is found, a warning appears.</li>\n",
        "    <li>‚ö†Ô∏è If an invalid format is selected, an error message is displayed.</li>\n",
        "  </ul>\n",
        "\n",
        "  <p style=\"font-weight: bold; font-size: 16px; color: #28A745;\">üöÄ Click \"Save Article\" to store your work in the desired format!</p>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "b890185287ff44deb49f28711deffae7",
            "ef156e32fc5246f5ade40ef93249ba1b",
            "bd63dcc3d2d94426aef68cb2930caafd",
            "603f78dff1a84a25b551c9b2f4e82043",
            "f32d79911f5b4642a83dd48e171a8a5c",
            "e65b1364dec44a29a350a43ca749a43d",
            "f2ad90b7f79142f09021f0515354d836",
            "ee09e5c3faf04a8d9c782dcc4a737ca4",
            "0cf92cf423294fe999b66421539cc483"
          ]
        },
        "id": "dloCosIxay0D",
        "outputId": "9204d5ff-5c25-42f1-dea5-01146f8150bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Article:', options=('LL1 Full Article', 'Gemini Enhanced Article'), value='LL1 Full Arti‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b890185287ff44deb49f28711deffae7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Format:', index=1, options=('TXT', 'PDF', 'DOCX'), value='PDF')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "603f78dff1a84a25b551c9b2f4e82043"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='primary', description='Save Article', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2ad90b7f79142f09021f0515354d836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ **Formatted LL1 Full Article saved as ll1_full_article.pdf!**\n",
            "\n",
            "‚úÖ **Formatted Gemini Enhanced Article saved as gemini_enhanced_article.pdf!**\n",
            "\n",
            "‚úÖ **Formatted LL1 Full Article saved as ll1_full_article.docx!**\n",
            "\n",
            "‚úÖ **Formatted LL1 Full Article saved as ll1_full_article.txt!**\n",
            "\n",
            "‚úÖ **Formatted Gemini Enhanced Article saved as gemini_enhanced_article.txt!**\n",
            "\n",
            "‚úÖ **Formatted Gemini Enhanced Article saved as gemini_enhanced_article.docx!**\n",
            "\n",
            "‚úÖ **Formatted LL1 Full Article saved as ll1_full_article.docx!**\n"
          ]
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from fpdf import FPDF\n",
        "import docx  # For DOCX saving\n",
        "import re  # Added for improved heading detection\n",
        "\n",
        "# === UI Elements ===\n",
        "article_dropdown = widgets.Dropdown(\n",
        "    options=[\"LL1 Full Article\", \"Gemini Enhanced Article\"],\n",
        "    description=\"Article:\",\n",
        "    value=\"LL1 Full Article\"  # Default selection\n",
        ")\n",
        "\n",
        "format_dropdown = widgets.Dropdown(\n",
        "    options=[\"TXT\", \"PDF\", \"DOCX\"],\n",
        "    description=\"Format:\",\n",
        "    value=\"PDF\"  # Default selection\n",
        ")\n",
        "\n",
        "save_button = widgets.Button(description=\"Save Article\", button_style='primary')\n",
        "\n",
        "display(article_dropdown, format_dropdown, save_button)\n",
        "\n",
        "# === PDF Class ===\n",
        "class PDF(FPDF):\n",
        "    \"\"\"Custom PDF class without a border.\"\"\"\n",
        "    def header(self):\n",
        "        pass  # No border or header\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Converts unsupported Unicode characters & removes Markdown symbols.\"\"\"\n",
        "    replacements = {\n",
        "        \"‚Ä¢\": \"-\", \"‚Äú\": '\"', \"‚Äù\": '\"', \"‚Äò\": \"'\", \"‚Äô\": \"'\",\n",
        "        \"‚Äì\": \"-\", \"‚Äî\": \"-\", \"**\": \"\", \"*\": \"\"  # Removes asterisks properly\n",
        "    }\n",
        "    for old, new in replacements.items():\n",
        "        text = text.replace(old, new)\n",
        "    return text\n",
        "\n",
        "def save_article(article_choice, format_choice):\n",
        "    \"\"\"Formats and saves the article in the chosen format without breaking UI.\"\"\"\n",
        "    global article_text, enhanced_article_text\n",
        "\n",
        "    if article_choice == \"LL1 Full Article\":\n",
        "        article_content = article_text.value.strip()\n",
        "    else:\n",
        "        article_content = enhanced_article_text.value.strip()\n",
        "\n",
        "    if not article_content:\n",
        "        print(f\"\\n‚ö†Ô∏è **No content found for {article_choice}! Generate it first.**\")\n",
        "        return\n",
        "\n",
        "    filename = f\"{article_choice.lower().replace(' ', '_')}.{format_choice.lower()}\"\n",
        "\n",
        "    # === PDF Saving ===\n",
        "    if format_choice == \"PDF\":\n",
        "        lines = article_content.strip().split(\"\\n\")\n",
        "        title = clean_text(lines[0].strip())\n",
        "        content = clean_text(\"\\n\".join(lines[1:]).strip())\n",
        "\n",
        "        #word_count = sum(len(line.split()) for line in content.split(\"\\n\") if line.strip())\n",
        "\n",
        "        pdf = PDF()\n",
        "        pdf.set_auto_page_break(auto=True, margin=15)\n",
        "        pdf.add_page()\n",
        "\n",
        "        # **Title Formatting**\n",
        "        pdf.set_font(\"Times\", \"B\", 18)\n",
        "        pdf.multi_cell(0, 10, title, align=\"C\")\n",
        "        pdf.ln(10)\n",
        "\n",
        "        pdf.set_font(\"Times\", \"\", 12)\n",
        "\n",
        "        # **Content Processing**\n",
        "        for line in content.split(\"\\n\"):\n",
        "            line = line.strip()\n",
        "            if re.match(r'^[IVXLCDM]+\\.', line):  # Improved heading detection\n",
        "                pdf.set_font(\"Times\", \"B\", 12)  # Headings: Bold, capitalized\n",
        "                pdf.multi_cell(0, 8, line.upper(), align=\"L\")\n",
        "                pdf.ln(5)\n",
        "                pdf.set_font(\"Times\", \"\", 12)  # Reset to normal font\n",
        "            elif line.startswith(\"* \") or line.startswith(\"- \"):\n",
        "                pdf.cell(10)\n",
        "                bullet_text = f\"- {line[2:]}\"\n",
        "                pdf.set_font(\"Times\", \"B\", 12)  # Bullets: Bold and consistent\n",
        "                pdf.cell(0, 8, bullet_text, ln=True)\n",
        "                pdf.set_font(\"Times\", \"\", 12)\n",
        "            else:\n",
        "                pdf.multi_cell(0, 8, line, align=\"J\")\n",
        "\n",
        "        pdf.ln(10)\n",
        "        #pdf.set_font(\"Times\", \"I\", 11)\n",
        "        #pdf.cell(0, 10, f\"Total Word Count: {word_count}\", ln=True, align=\"C\")\n",
        "\n",
        "        pdf.output(filename)\n",
        "        print(f\"\\n‚úÖ **Formatted {article_choice} saved as {filename}!**\")\n",
        "\n",
        "    # === TXT Saving ===\n",
        "    elif format_choice == \"TXT\":\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(article_content)\n",
        "        print(f\"\\n‚úÖ **Formatted {article_choice} saved as {filename}!**\")\n",
        "\n",
        "    # === DOCX Saving ===\n",
        "    elif format_choice == \"DOCX\":\n",
        "        doc = docx.Document()\n",
        "        doc.add_paragraph(article_content)\n",
        "        doc.save(filename)\n",
        "        print(f\"\\n‚úÖ **Formatted {article_choice} saved as {filename}!**\")\n",
        "\n",
        "# === Button Action ===\n",
        "def on_save_article(b):\n",
        "    article_choice = article_dropdown.value\n",
        "    format_choice = format_dropdown.value\n",
        "    save_article(article_choice, format_choice)\n",
        "\n",
        "save_button.on_click(on_save_article)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b2b5f1853c934d3f8c7cceaa3291ae9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Title:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_95270b4bcc9c40b0939711ace99482c6",
            "placeholder": "Enter the article title...",
            "rows": null,
            "style": "IPY_MODEL_6388fcf6054e43829a2c90172aa81cb7",
            "value": "Large Language Models"
          }
        },
        "95270b4bcc9c40b0939711ace99482c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6388fcf6054e43829a2c90172aa81cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fb6a7466fdb4aaf8e90c7cecc800fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Description:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_993cae1218be4ab38b653030a2ea8329",
            "placeholder": "(Optional) Enter a short article description...",
            "rows": null,
            "style": "IPY_MODEL_b7e8739684b9434b89356014d69e0880",
            "value": ""
          }
        },
        "993cae1218be4ab38b653030a2ea8329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "100px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b7e8739684b9434b89356014d69e0880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93b652fbcab146849892407dce7cbb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Word Count:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_15dd4fcc4ba041cdbef86ce76efb1c9c",
            "step": 1,
            "style": "IPY_MODEL_18a1ecd9346842ef94e9c87f5e12b759",
            "value": 1000
          }
        },
        "15dd4fcc4ba041cdbef86ce76efb1c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18a1ecd9346842ef94e9c87f5e12b759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecb2d92e3ce74a54a3a2be8d432d2f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Generate Structure",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_562049c199594c9b860fd7c7b3c83767",
            "style": "IPY_MODEL_6207b95a88ef4cd1840bb6fcce001c92",
            "tooltip": ""
          }
        },
        "562049c199594c9b860fd7c7b3c83767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6207b95a88ef4cd1840bb6fcce001c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "14f9bce69d8345d4acc3d47ee539cc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Structure:",
            "description_tooltip": null,
            "disabled": true,
            "layout": "IPY_MODEL_043c3ebe091b4fa095cc29276486d9ad",
            "placeholder": "Generated structure will appear here...",
            "rows": null,
            "style": "IPY_MODEL_cb1531a35fd04d689faab0bc7a37feb0",
            "value": "Based on the final critique, I will revise the article structure to improve its logical flow, clarity, and coherence. Here is the revised structure:\n\n**I. Introduction (approx. 100 words)**\n\n* A surprising fact about the rapid development of large language models (LLMs): \"Did you know that LLMs have evolved from simple chatbots to sophisticated language understanding systems in just a few years?\"\n* Brief overview of the topic: LLMs and their significance in modern technology\n* Thesis statement: This article will delve into the concept of large language models, exploring their capabilities, applications, and limitations in various fields.\n\n**II. The Evolution of Language Models (approx. 200 words)**\n\n* Historical context: language models and their development over time\n* Key figures and their contributions to the development of LLMs\n* Explanation of neural networks and recurrent neural networks (RNNs): \"In simple terms, neural networks are artificial intelligence systems that mimic the human brain, while RNNs are a type of neural network that can process sequential data, such as speech or text.\"\n* Key milestones in the development of LLMs\n\n**III. Applications of Large Language Models (approx. 350 words)**\n\n* Natural Language Processing (NLP) and its applications: chatbots, sentiment analysis, language translation, and more\n* Concrete examples of how LLMs are being used in real-world applications, including case studies or examples from well-known companies or industries\n* Discussion of the ethical implications of these applications\n\n**IV. Challenges and Limitations of Large Language Models (approx. 250 words)**\n\n* Specific examples of biases and errors in LLMs, including cases where LLMs have made mistakes or perpetuated biases\n* Explanation of the economic implications of LLMs, including potential job displacement and the cost of developing and maintaining LLMs\n* Discussion of the potential risks and consequences of relying on LLMs, such as misinformation and job displacement\n* Future directions for improving LLMs, including addressing biases, increasing transparency, and more\n\n**V. Conclusion (approx. 100 words)**\n\n* Summary of the main points: LLM capabilities, applications, and limitations\n* Discussion of the potential for LLMs to be used for positive social change, such as in education or accessibility for people with disabilities\n* Final thoughts on the importance of understanding and utilizing LLMs responsibly.\n\nTotal word count: 1000 words.\n\nChanges made:\n\n* Added a surprising fact to the introduction to engage the reader\n* Expanded the historical context in section II to provide a better understanding of the development of LLMs\n* Added concrete examples to section III to illustrate the applications of LLMs\n* Increased the word count for section IV to provide more comprehensive coverage of challenges and limitations\n* Emphasized the potential for LLMs to be used for positive social change in the conclusion\n\nI hope this revised structure meets the requirements and is fully optimized with logical organization, clarity, and coherence."
          }
        },
        "043c3ebe091b4fa095cc29276486d9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "cb1531a35fd04d689faab0bc7a37feb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "171194b52a9c40f5b0ed81721b57371b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "Critique Structure",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ac80b230d64c48949dc7345fe1dbabff",
            "style": "IPY_MODEL_6ffb032d2bf644f89c75ef9839770aea",
            "tooltip": ""
          }
        },
        "ac80b230d64c48949dc7345fe1dbabff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ffb032d2bf644f89c75ef9839770aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "910851ac39c049b182cb17d13cdd85b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Rewrite Structure",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_671ac7f95b6d423dba17bbc23d1ea683",
            "style": "IPY_MODEL_f4d3e576de704d90813f17dd1527e5e8",
            "tooltip": ""
          }
        },
        "671ac7f95b6d423dba17bbc23d1ea683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4d3e576de704d90813f17dd1527e5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b62fb54fef76434babb662a9d98bdb18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "warning",
            "description": "Final Critique",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_1b6043958e3548d6a514bdd84f277bb9",
            "style": "IPY_MODEL_8d58905f45e84a94b19cd2a0ebc24aed",
            "tooltip": ""
          }
        },
        "1b6043958e3548d6a514bdd84f277bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d58905f45e84a94b19cd2a0ebc24aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "eef4fe4631b1447e9cf24b618454156b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Final Review",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f9025b971eeb4254b73c016f64291f1b",
            "style": "IPY_MODEL_2d8c263f10f44064a3e341e7af3eadfe",
            "tooltip": ""
          }
        },
        "f9025b971eeb4254b73c016f64291f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d8c263f10f44064a3e341e7af3eadfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a68345f23be4493188a7599955114d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Generate Final Article",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9a24b7dec425410f8dbf63c8a7f9c58e",
            "style": "IPY_MODEL_f110ad2bc3614ccbb8c0c9e4eddac2f6",
            "tooltip": ""
          }
        },
        "9a24b7dec425410f8dbf63c8a7f9c58e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f110ad2bc3614ccbb8c0c9e4eddac2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "020c874b304445eea17787399c8c44c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6f36a14d033f49d2a63cd068f0084e5f",
            "placeholder": "Generated article will appear here...",
            "rows": null,
            "style": "IPY_MODEL_8457b51978bc440289aefe69d3833878",
            "value": "**Large Language Models: A New Era in Artificial Intelligence**\n\nDid you know that large language models (LLMs) have evolved from simple chatbots to sophisticated language understanding systems in just a few years? This rapid development has transformed the way we interact with technology, enabling applications that were previously unimaginable. In this article, we will delve into the concept of large language models, exploring their capabilities, applications, and limitations in various fields.\n\n**The Evolution of Language Models**\n\nThe concept of language models dates back to the 1960s, when the first chatbots were developed. However, it wasn't until the 2010s that LLMs began to take shape. Key figures such as Geoffrey Hinton, Yann LeCun, and Yoshua Bengio made significant contributions to the development of LLMs. Neural networks, a type of artificial intelligence system that mimics the human brain, were a crucial component in the development of LLMs. Recurrent neural networks (RNNs), in particular, allowed LLMs to process sequential data, such as speech or text.\n\nThe development of LLMs accelerated in the 2010s, with milestones such as the introduction of the Word2Vec algorithm in 2013 and the development of the Transformer model in 2017. Today, LLMs are being used in a wide range of applications, from customer service chatbots to medical diagnosis.\n\n**Applications of Large Language Models**\n\nLLMs have numerous applications in the field of Natural Language Processing (NLP). One of the most significant applications is in chatbots, which use LLMs to understand and respond to user queries. LLMs are also being used in sentiment analysis, language translation, and text summarization.\n\nConcrete examples of LLM applications can be seen in industries such as healthcare and finance. For instance, IBM's Watson for Oncology uses LLMs to analyze patient data and provide personalized treatment options. Similarly, banks such as JPMorgan Chase are using LLMs to analyze customer data and provide personalized financial advice.\n\nHowever, the applications of LLMs also raise ethical concerns. For instance, the use of LLMs in hiring processes has raised concerns about bias and discrimination. The use of LLMs in healthcare has also raised concerns about the potential for misdiagnosis and misinformation.\n\n**Challenges and Limitations of Large Language Models**\n\nDespite their many benefits, LLMs are not without their challenges and limitations. One of the most significant challenges is bias, which can be built into LLMs through the data used to train them. This bias can result in inaccurate or discriminatory outputs.\n\nAnother challenge is the lack of transparency in LLMs. It can be difficult to understand how LLMs arrive at their outputs, which can make it challenging to identify and correct errors.\n\nThe economic implications of LLMs are also significant. The development and maintenance of LLMs require significant resources, which can be a barrier to entry for smaller companies. Additionally, the use of LLMs can displace jobs, particularly in industries such as customer service and data entry.\n\n**Conclusion**\n\nLarge language models have come a long way in a short amount of time, and their applications are vast and varied. However, it is essential to understand the challenges and limitations of LLMs and to approach their development and deployment with caution.\n\nDespite these challenges, LLMs have the potential to be used for positive social change. For instance, LLMs can be used to improve accessibility for people with disabilities, such as language translation software for sign language interpreters. LLMs can also be used to improve education, such as AI-powered tutors that can provide personalized learning recommendations.\n\nAs we move forward with the development and deployment of LLMs, it is essential that we prioritize transparency, accountability, and ethics. By doing so, we can ensure that LLMs are used to benefit society, rather than to perpetuate biases and errors.\n\n**Total Word Count: 1000**"
          }
        },
        "6f36a14d033f49d2a63cd068f0084e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "300px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8457b51978bc440289aefe69d3833878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4207deddbce42cdb6d24b806c9fac5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Enhance with Gemini",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d8e9b255deaf4ef79d1992baf9ea74f4",
            "style": "IPY_MODEL_b0fc2f9ea87449888e31967bf57af6d0",
            "tooltip": ""
          }
        },
        "d8e9b255deaf4ef79d1992baf9ea74f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0fc2f9ea87449888e31967bf57af6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ddb4ac0cf9bd4f418c40f803ab8b37f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_26fc96eb60e94f549293d6b6afaa1bb0",
            "placeholder": "Enhanced article will appear here...",
            "rows": null,
            "style": "IPY_MODEL_30c7c3fedb6c4da29eb6bddd0d369c88",
            "value": "**Title:** The Rise of Large Language Models: Ushering in a New Era of Language Technology\n\nIn an era where technology advances at an unprecedented pace, large language models (LLMs) have emerged as a transformative force in artificial intelligence (AI). Their rapid evolution has pushed the boundaries of language understanding, paving the way for countless applications that were once deemed impossible.\n\n**The Dawn of Language Models**\n\nThe concept of language models has its roots in the 1960s, with the advent of simple chatbots. However, it wasn't until the 2010s that LLMs truly blossomed. Visionaries like Geoffrey Hinton, Yann LeCun, and Yoshua Bengio laid the foundation for their development.\n\nNeural networks, inspired by the intricacies of the human brain, became instrumental in the creation of LLMs. Recurrent neural networks (RNNs), in particular, empowered LLMs to unravel the intricate sequences of spoken or written language.\n\n**LLMs: A Quantum Leap in NLP**\n\nThe development of LLMs accelerated dramatically in the 2010s. Milestones like the Word2Vec algorithm in 2013 and the revolutionary Transformer model in 2017 propelled LLMs into the limelight. Today, they are deployed in a diverse array of applications, from conversational chatbots to life-saving medical diagnoses.\n\nLLMs have become a game-changer in the realm of Natural Language Processing (NLP). Seamlessly understanding and responding to user inquiries, chatbots powered by LLMs are revolutionizing customer service. Moreover, LLMs excel in sentiment analysis, language translation, and text summarization, making language barriers a thing of the past.\n\nReal-world examples of LLM applications abound. IBM's Watson for Oncology harnesses the power of LLMs to unravel patient data, delivering personalized treatment plans. Leading banks like JPMorgan Chase leverage LLMs to decipher customer data, offering tailored financial guidance.\n\n**Challenges and Ethical Considerations**\n\nWhile LLMs offer tremendous potential, they are not immune to challenges and ethical dilemmas. Bias is an inherent concern, as LLMs can inherit biases from the data they are trained on. This can lead to skewed or discriminatory outcomes.\n\nTransparency is another crucial consideration. It can be challenging to decipher how LLMs arrive at their conclusions, hindering error detection and correction.\n\nFurthermore, the economic impact of LLMs cannot be overlooked. Their development and upkeep require substantial resources, potentially limiting access for smaller businesses. Additionally, the widespread use of LLMs could displace jobs in sectors like customer service and data entry.\n\n**Unlocking the Future with LLMs**\n\nDespite these challenges, LLMs possess immense promise for positive social change. They can enhance accessibility for those with disabilities, providing sign language translation for deaf individuals. Furthermore, they can revolutionize education, offering personalized learning recommendations through AI-powered tutors.\n\nAs we continue to explore the boundless possibilities of LLMs, it is paramount to prioritize transparency, accountability, and ethical considerations. By forging a path that upholds these principles, we can harness the power of LLMs to uplift society, bridging knowledge gaps and fostering progress.\n\n**Total Word Count: 1000**"
          }
        },
        "26fc96eb60e94f549293d6b6afaa1bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "300px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "30c7c3fedb6c4da29eb6bddd0d369c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b890185287ff44deb49f28711deffae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "LL1 Full Article",
              "Gemini Enhanced Article"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Article:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_ef156e32fc5246f5ade40ef93249ba1b",
            "style": "IPY_MODEL_bd63dcc3d2d94426aef68cb2930caafd"
          }
        },
        "ef156e32fc5246f5ade40ef93249ba1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd63dcc3d2d94426aef68cb2930caafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "603f78dff1a84a25b551c9b2f4e82043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "TXT",
              "PDF",
              "DOCX"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Format:",
            "description_tooltip": null,
            "disabled": false,
            "index": 2,
            "layout": "IPY_MODEL_f32d79911f5b4642a83dd48e171a8a5c",
            "style": "IPY_MODEL_e65b1364dec44a29a350a43ca749a43d"
          }
        },
        "f32d79911f5b4642a83dd48e171a8a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e65b1364dec44a29a350a43ca749a43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2ad90b7f79142f09021f0515354d836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Save Article",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ee09e5c3faf04a8d9c782dcc4a737ca4",
            "style": "IPY_MODEL_0cf92cf423294fe999b66421539cc483",
            "tooltip": ""
          }
        },
        "ee09e5c3faf04a8d9c782dcc4a737ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf92cf423294fe999b66421539cc483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}